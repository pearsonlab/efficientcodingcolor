John:   Look at spectrum of eigenvalues 
	Look at % variance explained as a function of number of PCs
Greg: Plot that on a log scale vs linear scale 
Greg: Look at 4th, 5th and 6th PCs

John: How many mosaics do I have right now? 


*Greg: To better optimization, we could have the kernel centers be fixed 


David: Look at how well the algorithm converges based on the "parameters". 

Classify neurons: 
Gaussian mixture model in PC space 
K-means is also an option
The correct clustering should not have neurons in the same type overlapping each other spatially
Trick: Randomly initialize like 50 times and pick the best one. They will get stuck in local minima 


Greg: 3rd PC is capturing the differences in the surround 

John: 1st idea: Add W*W^T as a penalty objective for the start of training. 
2nd idea: Change ratio of first three PCs in LMS space 
50/30/20



Reviewer said that alignement vs anti-alignment doesn't account for a lot of the variance (but still more than red green). 

H1 and H2 horizontal cells.
H1 provides input to L + M
H2 provides input to S 


Greg said I'm putting the cart before the horse because I assume what the brain does is optimal (lol I mean he's not wrong)