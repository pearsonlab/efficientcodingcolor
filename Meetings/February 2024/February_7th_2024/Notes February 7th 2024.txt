scipy.optimize is better than pytorch for fitting DoG 
BFGS or nelder-mead 
They take the second derivative, so its faster 

Greg: 
Should express a, b, c d parameters in terms
of what they are, not just the parameter name. 

DoG fits are degenerate, they are multiple solutions for 
same RFs. Its normal that parameter fits don't align perfectly


To do:
***DoG parameter plots:
Instead of comparing parameter plots,
you show radial averages for DoG vs fitted DoG

Plot residuals between RF and DoG fit, as a funciton of distance. 

Let's plot zero-crossing instead of precision of the center
in the mosaics. 

** Make mosaic videos for each individual cluster 
Try to overlay pairs of mosaics 

** Go hunt for misclustered cells, does that improve
mosaic?
E.g. OFF parvo with -S inputs. Move one cell that's wrongly
clustered and move it to the OFF magno. See if that improves
the OFF magno mosaic!! 

***Rerun this with 3 channels, but L, M and S inputs are the
exact same. L = M, S = M. 
Set M, L. Or M = 0. 

John: Need less cells to get complete mosaics if there's 
less pixels in the inputs (smaller patch). 

LR plateau: Smooth version, only update minimum if 4 sd
from the mean. Also estimate sd using a running estimate. 

***Reduce field of view to 12x12 

--------------
David corner

1. Running Greg's experiments. The point is to figure out if it converges well or not. 
a) All three channels are the same
b) Set L = M, and/or S = M. 

2. Make mosaic videos + change circles to be zero-crossing 
 With 300 neurons 18x18
And with 500+ neurons 12x12. 

3. Go hunt for misclustered cells and see if that improves the mosaic :) 

4 (minor). Show radial averages of RF vs fitted DoG. 


